{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1580cb67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertForSequenceClassification' from 'transformers' (E:\\Anaconda\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BertForSequenceClassification' from 'transformers' (E:\\Anaconda\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 数据加载与预处理\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"加载并清洗评论数据\"\"\"\n",
    "    df = pd.read_csv(netease_comments_167827.csv, encoding='utf-8')\n",
    "    print(f\"原始数据量: {len(df)}条\")\n",
    "    \n",
    "    # 基础清洗\n",
    "    df = df.dropna(subset=['content'])  # 删除空评论\n",
    "    df['content'] = df['content'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))  # 去标点\n",
    "    df['content'] = df['content'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())  # 去空格\n",
    "    \n",
    "    # 中文分词\n",
    "    print(\"正在进行中文分词...\")\n",
    "    tqdm.pandas(desc=\"分词进度\")\n",
    "    df['seg_content'] = df['content'].progress_apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 2. 情感分析模型\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self, model_name=\"bert-base-chinese\"):\n",
    "        \"\"\"初始化BERT情感分析模型\"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "        self.label_map = {0: \"负面\", 1: \"中性\", 2: \"正面\"}\n",
    "        \n",
    "    def predict(self, texts, batch_size=16):\n",
    "        \"\"\"批量预测文本情感\"\"\"\n",
    "        results = []\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"情感分析进度\"):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = self.tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=128, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            results.extend(preds.numpy())\n",
    "        return [self.label_map[p] for p in results]\n",
    "\n",
    "# 3. 可视化分析\n",
    "def visualize_results(df):\n",
    "    \"\"\"生成分析图表\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 情感分布饼图\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('情感分布比例')\n",
    "    \n",
    "    # 词云生成\n",
    "    plt.subplot(2, 2, 2)\n",
    "    text = ' '.join(df['seg_content'])\n",
    "    wordcloud = WordCloud(\n",
    "        font_path='SimHei.ttf', \n",
    "        width=800, \n",
    "        height=600, \n",
    "        background_color='white'\n",
    "    ).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.title('高频词云')\n",
    "    \n",
    "    # 点赞与情感关系\n",
    "    plt.subplot(2, 2, 3)\n",
    "    df.boxplot(column='like_count', by='sentiment', showfliers=False)\n",
    "    plt.title('不同情感的点赞数分布')\n",
    "    plt.suptitle('')\n",
    "    plt.xlabel('情感类型')\n",
    "    \n",
    "    # 时间趋势分析（如果有时间字段）\n",
    "    if 'time' in df.columns:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        df['date'] = pd.to_datetime(df['time']).dt.date\n",
    "        daily_sentiment = df.groupby(['date', 'sentiment']).size().unstack()\n",
    "        daily_sentiment.plot(kind='line')\n",
    "        plt.title('情感趋势变化')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. 主流程\n",
    "def main():\n",
    "    # 加载数据（替换为你的文件路径）\n",
    "    file_path = \"netease_comments_167827.csv\"  # 确保包含content字段\n",
    "    df = load_and_clean_data(file_path)\n",
    "    \n",
    "    # 情感分析（使用预训练BERT模型）\n",
    "    print(\"\\n正在进行情感分析...\")\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    sample_size = min(1000, len(df))  # 限制分析数量（可选）\n",
    "    df_sample = df.sample(sample_size, random_state=42) if sample_size < len(df) else df\n",
    "    df_sample['sentiment'] = analyzer.predict(df_sample['content'].tolist())\n",
    "    \n",
    "    # 结果分析\n",
    "    print(\"\\n情感分类报告:\")\n",
    "    print(classification_report(\n",
    "        df_sample['sentiment'], \n",
    "        df_sample['sentiment'], \n",
    "        target_names=['负面', '中性', '正面']\n",
    "    ))\n",
    "    \n",
    "    # 可视化\n",
    "    visualize_results(df_sample)\n",
    "    \n",
    "    # 保存结果\n",
    "    output_path = \"sentiment_analysis_results.csv\"\n",
    "    df_sample.to_csv(output_path, index=False, encoding='utf_8_sig')\n",
    "    print(f\"\\n分析结果已保存到: {output_path}\")\n",
    "\n",
    "# 运行主程序\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0de50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas                         导入成功 | 版本: 1.5.3\n",
      "✅ numpy                          导入成功 | 版本: 1.24.3\n",
      "✅ jieba                          导入成功 | 版本: 0.42.1\n",
      "✅ sklearn.model_selection        导入成功 | 版本: 1.3.0\n",
      "✅ sklearn.metrics                导入成功 | 版本: 1.3.0\n",
      "✅ matplotlib.pyplot              导入成功 | 版本: 3.7.1\n",
      "✅ wordcloud                      导入成功 | 版本: 1.9.4\n",
      "✅ transformers                   导入成功 | 版本: 2.1.1\n",
      "✅ transformers                   导入成功 | 版本: 2.1.1\n",
      "❌ torch                          未安装\n",
      "✅ tqdm                           导入成功 | 版本: 4.65.0\n"
     ]
    }
   ],
   "source": [
    "# 检查每个库是否能正常导入\n",
    "libs = [\n",
    "    ('pandas', 'pd'),\n",
    "    ('numpy', 'np'),\n",
    "    ('jieba', 'jieba'),\n",
    "    ('sklearn.model_selection', 'train_test_split'),\n",
    "    ('sklearn.metrics', 'classification_report'),\n",
    "    ('matplotlib.pyplot', 'plt'),\n",
    "    ('wordcloud', 'WordCloud'),\n",
    "    ('transformers', 'BertTokenizer'),\n",
    "    ('transformers', 'BertForSequenceClassification'),\n",
    "    ('torch', 'torch'),\n",
    "    ('tqdm', 'tqdm')\n",
    "]\n",
    "\n",
    "for lib, alias in libs:\n",
    "    try:\n",
    "        exec(f\"import {lib.split('.')[0]} as {alias}\")\n",
    "        version = eval(f\"{alias}.__version__\") if hasattr(eval(alias), '__version__') else \"版本信息不可用\"\n",
    "        print(f\"✅ {lib: <30} 导入成功 | 版本: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {lib: <30} 未安装\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {lib: <30} 导入错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的库\n",
    "!pip install snownlp wordcloud jieba\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from snownlp import SnowNLP\n",
    "from wordcloud import WordCloud\n",
    "import jieba\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 情感分析函数\n",
    "def analyze_sentiment(text):\n",
    "    try:\n",
    "        s = SnowNLP(text)\n",
    "        return s.sentiments\n",
    "    except:\n",
    "        return 0.5  # 中性作为默认值\n",
    "\n",
    "# 生成词云函数\n",
    "def generate_wordcloud(texts, title):\n",
    "    word_list = []\n",
    "    for text in texts:\n",
    "        words = jieba.cut(text)\n",
    "        word_list.extend([word for word in words if len(word) > 1 and word not in ['哈哈', '啊啊', '呜呜']])\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        font_path='SimHei.ttf',\n",
    "        background_color='white',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        max_words=100\n",
    "    ).generate(' '.join(word_list))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 情感分析\n",
    "display(Markdown(\"## 🎭 情感分析\"))\n",
    "df['情感分值'] = df['评论内容'].apply(analyze_sentiment)\n",
    "\n",
    "# 情感分布可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['情感分值'], bins=20, kde=True)\n",
    "plt.title('评论情感分值分布')\n",
    "plt.xlabel('情感分值 (0-1, 越接近1表示越积极)')\n",
    "plt.ylabel('评论数量')\n",
    "plt.show()\n",
    "\n",
    "# 情感分类\n",
    "df['情感分类'] = pd.cut(df['情感分值'], \n",
    "                      bins=[0, 0.3, 0.7, 1],\n",
    "                      labels=['负面', '中性', '正面'])\n",
    "\n",
    "# 情感分类统计\n",
    "sentiment_stats = df['情感分类'].value_counts(normalize=True).mul(100).round(1)\n",
    "display(Markdown(\"### 情感分类比例 (%)\"))\n",
    "display(sentiment_stats)\n",
    "\n",
    "# 情感分类饼图\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_stats, labels=sentiment_stats.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('评论情感分类比例')\n",
    "plt.show()\n",
    "\n",
    "# 点赞数与情感关系\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='情感分值', y='点赞数', alpha=0.6)\n",
    "plt.title('情感分值与点赞数的关系')\n",
    "plt.show()\n",
    "\n",
    "# 用户画像 - 活跃用户\n",
    "top_users = df['用户'].value_counts().head(5)\n",
    "display(Markdown(\"### 🏆 最活跃的5位用户 (评论次数最多)\"))\n",
    "display(top_users)\n",
    "\n",
    "# 用户画像 - 高影响力用户\n",
    "top_influencers = df.sort_values('点赞数', ascending=False).drop_duplicates('用户ID').head(5)[['用户', '点赞数', '评论内容']]\n",
    "display(Markdown(\"### 💪 最具影响力的5位用户 (单条评论点赞最多)\"))\n",
    "display(top_influencers)\n",
    "\n",
    "# 词云分析 - 全部评论\n",
    "display(Markdown(\"### ☁ 全部评论词云\"))\n",
    "generate_wordcloud(df['评论内容'], '全部评论词云')\n",
    "\n",
    "# 词云分析 - 正面评论\n",
    "display(Markdown(\"### 😊 正面评论词云 (情感分值 > 0.7)\"))\n",
    "positive_comments = df[df['情感分值'] > 0.7]['评论内容']\n",
    "generate_wordcloud(positive_comments, '正面评论词云')\n",
    "\n",
    "# 词云分析 - 负面评论\n",
    "display(Markdown(\"### 😞 负面评论词云 (情感分值 < 0.3)\"))\n",
    "negative_comments = df[df['情感分值'] < 0.3]['评论内容']\n",
    "generate_wordcloud(negative_comments, '负面评论词云')\n",
    "\n",
    "# IP属地分析\n",
    "if 'IP属地' in df.columns:\n",
    "    display(Markdown(\"### 🌍 用户地域分布\"))\n",
    "    location_stats = df['IP属地'].value_counts().head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    location_stats.plot(kind='bar')\n",
    "    plt.title('评论用户Top10地域分布')\n",
    "    plt.xlabel('地域')\n",
    "    plt.ylabel('评论数量')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# 时间分析\n",
    "display(Markdown(\"### ⏰ 评论时间分布\"))\n",
    "df['小时'] = df['评论时间'].dt.hour\n",
    "hourly_counts = df['小时'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_counts.plot(kind='bar')\n",
    "plt.title('24小时评论数量分布')\n",
    "plt.xlabel('小时')\n",
    "plt.ylabel('评论数量')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# 保存分析结果\n",
    "analysis_file = f'netease_analysis_{song_id}.csv'\n",
    "df.to_csv(analysis_file, index=False, encoding='utf-8-sig')\n",
    "display(Markdown(f\"💾 分析结果已保存为 {analysis_file}\"))\n",
    "\n",
    "# 总结报告\n",
    "display(Markdown(\"## 📝 分析总结报告\"))\n",
    "display(Markdown(f\"\"\"\n",
    "1. **情感分布**: 歌曲评论中正面情感占比 {sentiment_stats.get('正面', 0)}%，负面情感占比 {sentiment_stats.get('负面', 0)}%\n",
    "2. **活跃时间**: 评论高峰时段为 {hourly_counts.idxmax()}:00 时，共 {hourly_counts.max()} 条评论\n",
    "3. **热门地域**: 评论用户主要来自 {location_stats.index[0] if 'IP属地' in df.columns else '未知'}\n",
    "4. **内容特点**: 高频词汇可通过词云图直观查看，反映了听众的主要关注点\n",
    "5. **用户互动**: 最高点赞评论获得 {df['点赞数'].max()} 个赞，内容为 \"{df.sort_values('点赞数', ascending=False).iloc[0]['评论内容'][:30]}...\"\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b217730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情感模型优化与智能推荐系统\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snownlp import SnowNLP\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.models import Word2Vec\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 1. 数据准备（接续之前爬取的评论数据）\n",
    "df = pd.read_csv(f'netease_comments_{song_id}.csv')\n",
    "print(f\"原始数据量：{len(df)}条\")\n",
    "\n",
    "# 2. 情感模型优化（结合领域词典和加权机制）\n",
    "class EnhancedSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # 加载音乐领域情感词典\n",
    "        self.music_lexicon = {\n",
    "            '旋律': 0.8, '编曲': 0.7, '作词': 0.6, \n",
    "            '青春': 0.9, '回忆': 0.85, '经典': 0.75,\n",
    "            '难听': -0.9, '过时': -0.6, '失望': -0.7\n",
    "        }\n",
    "        self.base_analyzer = SnowNLP\n",
    "        \n",
    "    def analyze(self, text):\n",
    "        try:\n",
    "            # 基础情感分析\n",
    "            s = self.base_analyzer(text)\n",
    "            base_score = s.sentiments\n",
    "            \n",
    "            # 领域词典增强\n",
    "            words = jieba.lcut(text)\n",
    "            lexicon_score = np.mean([self.music_lexicon.get(word, 0) for word in words])\n",
    "            \n",
    "            # 时间加权（夜间评论情感放大）\n",
    "            hour = pd.to_datetime(df[df['评论内容'] == text]['评论时间'].iloc[0]).hour\n",
    "            time_weight = 1.2 if 0 <= hour < 6 else 1.0\n",
    "            \n",
    "            # 综合计算（基础分60% + 领域分40%）\n",
    "            final_score = (base_score*0.6 + np.tanh(lexicon_score)*0.4) * time_weight\n",
    "            return np.clip(final_score, 0, 1)\n",
    "        except:\n",
    "            return 0.5\n",
    "\n",
    "# 应用优化后的情感分析\n",
    "analyzer = EnhancedSentimentAnalyzer()\n",
    "df['优化情感分'] = df['评论内容'].progress_apply(analyzer.analyze)\n",
    "\n",
    "# 对比优化效果\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "df['情感分值'].hist(bins=20)\n",
    "plt.title('原始情感分布')\n",
    "plt.subplot(122)\n",
    "df['优化情感分'].hist(bins=20)\n",
    "plt.title('优化后情感分布')\n",
    "plt.show()\n",
    "\n",
    "# 3. 用户心理分析（LDA主题模型）\n",
    "def analyze_psychology(texts):\n",
    "    # 中文分词处理\n",
    "    chinese_stopwords = set(['的', '了', '和', '是', '我'])\n",
    "    processed_texts = [\n",
    "        [word for word in jieba.lcut(text) \n",
    "         if len(word) > 1 and word not in chinese_stopwords]\n",
    "        for text in texts\n",
    "    ]\n",
    "    \n",
    "    # 训练Word2Vec模型\n",
    "    w2v_model = Word2Vec(processed_texts, vector_size=100, window=5, min_count=2, workers=4)\n",
    "    \n",
    "    # TF-IDF向量化\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    tfidf = vectorizer.fit_transform([' '.join(t) for t in processed_texts])\n",
    "    \n",
    "    # LDA主题建模\n",
    "    lda = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "    lda.fit(tfidf)\n",
    "    \n",
    "    # 可视化主题词\n",
    "    def show_topics(model, feature_names, n_top_words):\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            display(Markdown(f\"**主题#{topic_idx+1}**: \" + \n",
    "                   \", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]])))\n",
    "    \n",
    "    show_topics(lda, vectorizer.get_feature_names_out(), 10)\n",
    "    \n",
    "    return lda.transform(tfidf)\n",
    "\n",
    "# 应用心理分析\n",
    "topic_probs = analyze_psychology(df['评论内容'])\n",
    "df['心理主题'] = topic_probs.argmax(axis=1)\n",
    "\n",
    "# 4. 用户聚类分析\n",
    "def user_clustering(features):\n",
    "    # 特征工程（情感分+点赞数+主题概率）\n",
    "    X = np.column_stack([\n",
    "        features['优化情感分'],\n",
    "        np.log1p(features['点赞数']),\n",
    "        topic_probs\n",
    "    ])\n",
    "    \n",
    "    # 寻找最佳聚类数\n",
    "    silhouette_scores = []\n",
    "    for k in range(2, 6):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        silhouette_scores.append(silhouette_score(X, labels))\n",
    "    \n",
    "    best_k = np.argmax(silhouette_scores) + 2\n",
    "    display(Markdown(f\"### 最佳聚类数：{best_k}（轮廓系数{max(silhouette_scores):.2f}）\"))\n",
    "    \n",
    "    # 最终聚类\n",
    "    final_kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    df['用户类型'] = final_kmeans.fit_predict(X)\n",
    "    \n",
    "    # 可视化聚类结果\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for cluster in range(best_k):\n",
    "        cluster_data = df[df['用户类型'] == cluster]\n",
    "        plt.scatter(\n",
    "            cluster_data['优化情感分'], \n",
    "            np.log1p(cluster_data['点赞数']),\n",
    "            label=f'类型{cluster}'\n",
    "        )\n",
    "    plt.xlabel('优化情感分')\n",
    "    plt.ylabel('点赞数(log)')\n",
    "    plt.title('用户聚类分布')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 分析各类特征\n",
    "    display(Markdown(\"### 各类用户平均特征：\"))\n",
    "    display(df.groupby('用户类型').agg({\n",
    "        '优化情感分': 'mean',\n",
    "        '点赞数': 'median',\n",
    "        '心理主题': lambda x: x.mode()[0]\n",
    "    }))\n",
    "\n",
    "user_clustering(df)\n",
    "\n",
    "# 5. 智能推荐系统\n",
    "class MusicRecommender:\n",
    "    def __init__(self, user_data):\n",
    "        self.user_profiles = user_data\n",
    "        self.song_db = {\n",
    "            167827: {'title': '素颜', 'tags': ['青春', '回忆', '对唱']},\n",
    "            186016: {'title': '有何不可', 'tags': ['甜蜜', '初恋', '校园']},\n",
    "            287035: {'title': '雅俗共赏', 'tags': ['哲理', '人生', '思考']},\n",
    "            5260494: {'title': '乌鸦', 'tags': ['孤独', '成长', '治愈']}\n",
    "        }\n",
    "        \n",
    "    def recommend(self, user_id, top_n=3):\n",
    "        # 获取用户特征\n",
    "        user = self.user_profiles[self.user_profiles['用户ID'] == user_id].iloc[0]\n",
    "        \n",
    "        # 根据用户类型和心理主题匹配歌曲\n",
    "        if user['用户类型'] == 0:  # 高情感-怀旧型\n",
    "            candidates = [sid for sid, meta in self.song_db.items() \n",
    "                        if '回忆' in meta['tags']]\n",
    "        elif user['用户类型'] == 1:  # 理性分析型\n",
    "            candidates = [sid for sid, meta in self.song_db.items() \n",
    "                        if '思考' in meta['tags']]\n",
    "        else:  # 情感波动型\n",
    "            candidates = [sid for sid, meta in self.song_db.items() \n",
    "                        if '治愈' in meta['tags']]\n",
    "        \n",
    "        # 结合时间上下文\n",
    "        hour = pd.to_datetime(user['评论时间']).hour\n",
    "        if 0 <= hour < 6:  # 深夜时段推荐舒缓歌曲\n",
    "            candidates = [sid for sid in candidates \n",
    "                         if sid not in [186016]]  # 排除甜蜜歌曲\n",
    "        \n",
    "        # 返回推荐结果\n",
    "        return [(sid, self.song_db[sid]['title']) for sid in candidates[:top_n]]\n",
    "\n",
    "# 测试推荐系统\n",
    "recommender = MusicRecommender(df)\n",
    "sample_user = df.iloc[10]['用户ID']  # 取第10个用户作为示例\n",
    "rec_results = recommender.recommend(sample_user)\n",
    "\n",
    "display(Markdown(f\"### 为用户ID {sample_user} 生成的推荐：\"))\n",
    "for song_id, title in rec_results:\n",
    "    display(Markdown(f\"- {title} (ID: {song_id})\"))\n",
    "\n",
    "# 6. 系统评估\n",
    "def evaluate_recommendations():\n",
    "    # 模拟评估（实际应用需A/B测试）\n",
    "    user_types = df['用户类型'].unique()\n",
    "    accuracy = {}\n",
    "    \n",
    "    for utype in user_types:\n",
    "        users = df[df['用户类型'] == utype]['用户ID'].sample(5)\n",
    "        correct = 0\n",
    "        \n",
    "        for uid in users:\n",
    "            recs = [sid for sid, _ in recommender.recommend(uid)]\n",
    "            user_theme = df[df['用户ID'] == uid]['心理主题'].mode()[0]\n",
    "            \n",
    "            # 简单验证：推荐歌曲标签是否匹配用户主题\n",
    "            matched = any(\n",
    "                self.song_db[sid]['tags'][0] in ['回忆','青春'] \n",
    "                if user_theme == 0 else\n",
    "                self.song_db[sid]['tags'][0] in ['哲理','思考']\n",
    "                for sid in recs\n",
    "            )\n",
    "            correct += int(matched)\n",
    "        \n",
    "        accuracy[utype] = correct / 5\n",
    "    \n",
    "    display(Markdown(\"### 推荐准确率评估（抽样测试）：\"))\n",
    "    for utype, acc in accuracy.items():\n",
    "        display(Markdown(f\"- 类型{utype}用户：{acc*100:.1f}%\"))\n",
    "\n",
    "evaluate_recommendations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
